{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Investigation of the relationship between different stock market indexes from Developed and Emerging markets",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<div style='text-align: justify;'>\nThe relationship between international markets is an important issue for investors and researchers. Global markets present complex dynamics and \ninterdependences, forming a dynamic ecosystem where various financial products and assets interact. Markets are distinguished between developed\nand emerging according to their economic stability, political risk, financial system maturity, and market regulatory framework. Generally, developing\nmarkets tend to have higher systematic risk and growth expectations. To reduce the diversifiable risk and gain higher returns, portfolio managers \nadd stocks from emerging markets to portfolios that contain financial products from advanced markets. However, financial liberalization and global \ntrade agreements made financial markets more cointegrated. Consequently, the information transmission among the international stock markets can \ncause a financial contagious effect that vanishes potential diversification opportunities.\n</div>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Libraries\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom statsmodels.tsa.vector_ar.var_model import *\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.graphics.tsaplots import plot_acf",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def import_data(path):\n    # The data were downloaded from investment.com\n    # Load Market index logarithmic returns\n    df = pd.read_csv(path)\n\n    # Change column name\n    df.rename(columns={'Unnamed: 0': 'Date'}, inplace=True)\n\n    # Convert string to date time\n    df['Date'] = pd.to_datetime(df['Date'])\n\n    # Remove time\n    df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n\n    # Set frequency to avoid errors later in the VAR model\n    df['Date'] = pd.DatetimeIndex(df['Date']).to_period('B')\n    #df['Date'] = pd.DatetimeIndex(df['Date'])\n    # Set Datetime index\n    df.set_index('Date', inplace=True)\n    return df",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Load market index prices\npath1=\"market_indexes.csv\"\nmarket_price = import_data(path1)\nend=round(len(market_price)*0.9)\nmarket_price=market_price.iloc[0:end,:]\nlog_market_price = market_price.apply(np.log, axis=0)\nlog_market_ret = log_market_price - log_market_price.shift(1)\nlog_market_ret.dropna(inplace=True)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Stationarity  \n<div style='text-align: justify;'>\nWith time-series data an initial step is to test the presence of unit roots, in other words it should be tested if the market indices are stationary.\n</div>  \n\n## ADF unit root test  \n\n\nOne of the most used tests for stationarity was initially introduced by (Dickey & Fuller, 1979).\n\nThe unit root test model is given by:\n\n$$Δy_{t} = ψy_{t-1} + \\sum \\limits_{j=1} ^{p} a_{j}Δy_{t-j}  + e_{t}$$\n\n<div style='text-align: justify;'>\nWhere ψ is the coefficient of the first lag, p is the number of lags, αj is the coefficient of the first differences and et is the error term. The number of lags will be decided using the Akaike information criterion (AIC).\n</div>  \n\n<u>Hypothesis Testing.</u>  \nH0: ψ=0, yt is non-stationary  \nH1: ψ<0, yt is stationary  \n\n<div style='text-align: justify;'>\nThe general idea is that stationary time-series have a mean-reverting behavior and as a result previous values (yt-1) should provide relevant information for the movement of the series. In the case of ψ=0, the lagged value has no effect on the change of the variable and as a result, it is not stationary.\n</div>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from statsmodels.tsa.stattools import adfuller\ndef adf(df, j):\n\n    # Augmented Dickey-Fuller\n    # The number of lags was decided using AIC which is the default IC\n    # Maximum lag that is tested is 12\n    result = adfuller(df, maxlag=12, autolag='AIC')\n    if result[1] <= 0.05:\n        print('{} is stationary'.format(j))\n        print(\"p-value: {}\".format(result[1]))\n    else:\n        print('{} is non stationary'.format(j))\n        print('p-value: {}'.format(result[1]))\n    return \"{:.4f}\".format(result[1])",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### In levels",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "market_indices_columns = market_price.columns.values.tolist()\n\nstationarity_level = pd.DataFrame(0, index=['p-value'], columns=market_indices_columns)\n\nfor j in market_indices_columns:\n    stationarity_level[j] = adf(log_market_price[j], j)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "text": "Brazil is stationary\np-value: 0.04589581919058934\nChina is non stationary\np-value: 0.09376716288440134\nGermany is non stationary\np-value: 0.11706504529947537\nGreece is non stationary\np-value: 0.07383288104199594\nIndia is non stationary\np-value: 0.719903539990822\nUS is non stationary\np-value: 0.6187102275343025\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### In 1st difference",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "stationarity_1stdif = pd.DataFrame(0, index=['p-value'], columns=market_indices_columns)\nfor j in market_indices_columns:\n    stationarity_1stdif[j] = adf(log_market_ret[j], j)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "text": "Brazil is stationary\np-value: 2.2877586712872303e-19\nChina is stationary\np-value: 0.0\nGermany is stationary\np-value: 1.572522027603825e-24\nGreece is stationary\np-value: 4.4162919292700536e-20\nIndia is stationary\np-value: 1.1626021931785866e-17\nUS is stationary\np-value: 6.543707176570867e-20\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### Results  \n<div style='text-align: justify;'>\nThe result shows that all the variables apart from Brazil, are non-stationary in levels and stationary in first difference. \nAs Brazil is stationary in every case, the conclusion is that the other variables are integrated of order one, I(1) \nand they should be tested for cointegration. Brazil will not be tested for cointegration as only variables integrated of the same order can be cointegrated.\n</div>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Long-Term Relationship\n## Cointegration\n<div style='text-align: justify;'>\nThe concept of cointegration was introduced by (Engle & Granger, 1987). In the VAR setting, when some variables have a common stochastic trend, or simply they move together in a consistent and predictable way, it is said that these variables are cointegrated. It is important to state that the cointegration tests are implemented in levels, so the returns are not used.\n</div>  \n\n### Engle-Granger Two-step procedure\n<div style='text-align: justify;'>    \nThe cointegration can be tested using the Engle-Granger two-step procedure, which was proposed by (Engle & Granger, 1987).\nThe first step is to estimate using OLS a model that includes the variables that need to be tested for cointegration.\n</div>\n$$y_{1t} = a_{0} + \\sum \\limits_{j=1} ^{N} a_{j}y_{jt}  + e_{t}$$\n<div style='text-align: justify;'>\nWhere y1t, yjt are the selected variables, M is the total number of the selected variables, a0 is the intercept, aj is the coefficient of the j-th variable, where j=2...N, and et is the error-term.\n</div>\nOnce the parameters are obtained, then the estimation of the error term is of the form, \n$$ e_{t} = y_{1t} - a_{0} - \\sum \\limits_{j=1} ^{N} a_{j}y_{jt}$$\n\nThe second step is to test whether the residuals are stationary using the ADF unit test.\n\n<u>Hypothesis Testing.</u>   \nH0: et non-stationary, no-cointegration  \nH1: et stationary, cointegration  \n<div style='text-align: justify;'>\nTo identify relationships between two variables, the model has certain limitations such as being sensitive to the order of the lags and impacted by the ordering of variables. \n</div>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from statsmodels.tsa.stattools import coint\ndef engle_granger(df,col):\n    cointegration_pvalues = pd.DataFrame(0, index=col, columns=col)\n    for i in df:\n        for j in df:\n            if i != j:\n                result = coint(df[j], df[i])\n                cointegration_pvalues.loc[j, i] = result[1]\n    return cointegration_pvalues",
      "metadata": {
        "trusted": true
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Brazil is excluded from the data set for the cointegration tests\ncoint_ind = log_market_price.drop('Brazil',axis=1)\ncoint_ind.head()\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "               China   Germany    Greece      India        US\nDate                                                         \n2016-01-04  8.100544  9.238290  6.431524  10.151259  7.607213\n2016-01-05  8.097947  9.240879  6.425825  10.149579  7.609223\n2016-01-07  8.047190  9.208323  6.381393  10.120687  7.572035\n2016-01-08  8.066650  9.195160  6.373286  10.124001  7.561137\n2016-01-11  8.011919  9.192693  6.365920  10.119608  7.561990",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>China</th>\n      <th>Germany</th>\n      <th>Greece</th>\n      <th>India</th>\n      <th>US</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2016-01-04</th>\n      <td>8.100544</td>\n      <td>9.238290</td>\n      <td>6.431524</td>\n      <td>10.151259</td>\n      <td>7.607213</td>\n    </tr>\n    <tr>\n      <th>2016-01-05</th>\n      <td>8.097947</td>\n      <td>9.240879</td>\n      <td>6.425825</td>\n      <td>10.149579</td>\n      <td>7.609223</td>\n    </tr>\n    <tr>\n      <th>2016-01-07</th>\n      <td>8.047190</td>\n      <td>9.208323</td>\n      <td>6.381393</td>\n      <td>10.120687</td>\n      <td>7.572035</td>\n    </tr>\n    <tr>\n      <th>2016-01-08</th>\n      <td>8.066650</td>\n      <td>9.195160</td>\n      <td>6.373286</td>\n      <td>10.124001</td>\n      <td>7.561137</td>\n    </tr>\n    <tr>\n      <th>2016-01-11</th>\n      <td>8.011919</td>\n      <td>9.192693</td>\n      <td>6.365920</td>\n      <td>10.119608</td>\n      <td>7.561990</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "cointegration_pvalues = engle_granger(coint_ind, coint_ind.columns.values)\ncointegration = cointegration_pvalues.copy()\ncointegration[cointegration <= 0.05] = 'YES'\ncointegration[cointegration != 'YES'] = 'NO'\nfor i in range(len(cointegration)):\n    cointegration.iloc[i, i] = '-'\ncointegration.head()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 30,
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "        China Germany Greece India  US\nChina       -     YES     NO    NO  NO\nGermany   YES       -     NO    NO  NO\nGreece     NO      NO      -    NO  NO\nIndia      NO      NO     NO     -  NO\nUS         NO      NO     NO    NO   -",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>China</th>\n      <th>Germany</th>\n      <th>Greece</th>\n      <th>India</th>\n      <th>US</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>China</th>\n      <td>-</td>\n      <td>YES</td>\n      <td>NO</td>\n      <td>NO</td>\n      <td>NO</td>\n    </tr>\n    <tr>\n      <th>Germany</th>\n      <td>YES</td>\n      <td>-</td>\n      <td>NO</td>\n      <td>NO</td>\n      <td>NO</td>\n    </tr>\n    <tr>\n      <th>Greece</th>\n      <td>NO</td>\n      <td>NO</td>\n      <td>-</td>\n      <td>NO</td>\n      <td>NO</td>\n    </tr>\n    <tr>\n      <th>India</th>\n      <td>NO</td>\n      <td>NO</td>\n      <td>NO</td>\n      <td>-</td>\n      <td>NO</td>\n    </tr>\n    <tr>\n      <th>US</th>\n      <td>NO</td>\n      <td>NO</td>\n      <td>NO</td>\n      <td>NO</td>\n      <td>-</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### Results\nOnly China and Germany are pairwise-cointegrated.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Johansen cointegration test\nThis test is based on VECM model which is a transformation of the VAR model. The VECM model is suitable in cases where the variables exhibit cointegration.\nVECM(p) specification: \n\n$$ΔY_{t} = D_{t} + ΠY_{t-1} + \\sum \\limits_{j=1} ^{p-1} Γ_{j}ΔΥ_{t-j}  + e_{t}$$\n<div style='text-align: justify;'>\nDt is the intercept, while $Π$ and $Γ_{j}$ demonstrate the long and short-run relationship between the variables respectively. When the cointegration rank and the lag order of the model are selected, the estimation is implemented by maximum likelihood.\nThe Johansen test aims to define the number of cointegrating relationships and is mainly applied using two methods, the trace test, and the eigenvalue test. When Π=0, then there is no cointegration, as there is no long-run equilibrium between two or more variables. Intuitively, as the rank of a matrix denotes the maximum number of linearly independent vectors, then the rank of Π represents the number of independent linear combinations of the variables that are stationary.  \n</div>  \n\n<b>Trace Test</b>  \n<u>Hypothesis Testing.</u>    \nH0: rank(Π)=r  \nH1: rank(Π) ≥ r  \n<u>Trace Statistic:</u> \n$$Trace_{Stat} = -T\\sum \\limits_{i=r+1} ^{n} ln(1-\\hat{λ_{i}})$$\n\n<b>Maximum Eigenvalue Test</b>  \n<u>Hypothesis Testing.</u>   \nH0: rank(Π)=r  \nH1: rank(Π) ≥ r + 1  \n<u>Maximum Eigenvalue Statistic:</u>\n$$MAX_EIG_{Stat} = -Tln(1-\\hat{λ_{r+1}})$$\nFor r= 0,1, …... n-1",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from statsmodels.tsa.vector_ar.vecm import *\ndef multivariate_johansen(df, alpha=0.05):\n    \"\"\"Perform Johanson's Cointegration Test and Report Summary\"\"\"\n    out = coint_johansen(df,-1, 5)\n    d = {'0.90':0, '0.95':1, '0.99':2}\n    traces = out.lr1\n    cvts = out.cvt[:, d[str(1-alpha)]]\n    def adjust(val, length= 6): return str(val).ljust(length)\n    # Summary\n    print('Name   ::  Test Stat > C(95%)    =>   Signif  \\n', '--'*20)\n    for col, trace, cvt in zip(df.columns, traces, cvts):\n        print(adjust(col), ':: ', adjust(round(trace,2), 9), \">\", adjust(cvt, 8), ' =>  ' , trace > cvt)\n# Reference: https://gist.github.com/BioSciEconomist/197bd86ea61e0b4a49707af74a0b9f9c",
      "metadata": {
        "trusted": true
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "multivariate_johansen(coint_ind)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 33,
      "outputs": [
        {
          "name": "stdout",
          "text": "Name   ::  Test Stat > C(95%)    =>   Signif  \n ----------------------------------------\nChina  ::  50.48     > 60.0627   =>   False\nGermany ::  31.0      > 40.1749   =>   False\nGreece ::  15.54     > 24.2761   =>   False\nIndia  ::  5.19      > 12.3212   =>   False\nUS     ::  0.1       > 4.1296    =>   False\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### Results  \n\n<div style='text-align: justify;'>\nthe results of the Johansen test, employed by trace method and a lag order of five. As the test statistics are lower than the critical values, then the variables are not cointegrated.\nThe Johansen test was employed by trace method and a lag order of five. As the test statistics are lower than the critical values, then the variables are not cointegrated.\n</div>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Short-Term Relationship  \n## Granger-Causality test  \n<div style='text-align: justify;'>\nGranger causality test attempts to identify the causal relationships among the variables. The method was proposed by (Granger, 1969) and become famous by (Sims, 1972). In the bivariate case, it tries to examine the causal relationship between two variables (Y1, Y2). According to (Brooks, 2008), when Y1 Granger-cause Y2, then Y1 is able to forecast Y2 and in the VAR setting this happens when the lags of Y1 in the equation of Y2 are statistically significant. This is the case of unidirectional causality from Y1 to Y2. When Y2 also Granger-cause Y1, then this case is known as bi-directional causality.\n</div>  \n\nFrom the VAR(p) model, the equations of Y1 and Y2 are:  \n$$ Y_{1t} = A_{10} + \\sum \\limits _{j=1} ^{p}A_{11j}Y_{1t-j} + \\sum \\limits _{j=1} ^{p}A_{12j}Y_{2t-j} + e_{1t}$$\n\n$$ Y_{2t} = A_{20} + \\sum \\limits _{j=1} ^{p}A_{21j}Y_{1t-j} + \\sum \\limits _{j=1} ^{p}A_{22j}Y_{2t-j} + e_{2t}$$\nThe hypothesis testing can easily be implemented using the F-test statistic (or Wald statistic).  \n\n<u>Hypothesis testing for Y1 Granger-cause Y2:</u>  \nH0: Y1 fails to Granger-cause Y2 (the elements of A21 are 0)  \nH1: Y1 Granger-cause Y2 (the elements of A21 are different from 0)  \n\n<div style='text-align: justify;'>\nIt is important to note that Granger causality has a notion similar to correlation and not causation. It is a statistical method that identifies whether past values of one variable can predict the current or future values of another variable.\n</div>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from statsmodels.tsa.stattools import grangercausalitytests\ndef grangers_causality_matrix(data, variables, lag_order=3, test = 'ssr_chi2test', verbose=False):\n    # Code:\n    # https://towardsdatascience.com/granger-causality-and-vector-auto-regressive-model-for-time-series-forecasting-3226a64889a6\n    # https://phdinds-aim.github.io/time_series_handbook/04_GrangerCausality/04_GrangerCausality.html\n    dataset = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n    for c in dataset.columns:\n        for r in dataset.index:\n            test_result = grangercausalitytests(data[[r,c]], maxlag=lag_order, verbose=False)\n\n            \"\"\"x: array_like\n            The data for testing whether the time series in the second column Granger\n            causes the time series in the first column.\"\"\"\n\n            p_values = [round(test_result[i+1][0][test][1],4) for i in range(lag_order)]\n            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n\n            min_p_value = np.min(p_values)\n            # H0: X Fails to Granger-Cause Y\n            # H1: X Granger-Cause Y\n            if min_p_value <= 0.05:\n                dataset.loc[r,c] = \"YES\"\n            else:\n                dataset.loc[r, c] = \"NO\"\n    for i in range(len(dataset)):\n        dataset.iloc[i, i] = '-'\n    dataset.columns = [var + '_X' for var in variables]\n    dataset.index = [var + '_Y' for var in variables]\n    return dataset",
      "metadata": {
        "trusted": true
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# The Granger-Causality test is run for a lag order of five\npairwise_causality = grangers_causality_matrix(log_market_ret, variables = log_market_ret.columns, lag_order=5)\npairwise_causality.head(6)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 36,
      "outputs": [
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "          Brazil_X China_X Germany_X Greece_X India_X US_X\nBrazil_Y         -      NO       YES      YES     YES  YES\nChina_Y        YES       -       YES      YES     YES  YES\nGermany_Y       NO     YES         -      YES     YES  YES\nGreece_Y       YES     YES        NO        -     YES  YES\nIndia_Y        YES      NO       YES      YES       -  YES\nUS_Y           YES      NO       YES      YES     YES    -",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Brazil_X</th>\n      <th>China_X</th>\n      <th>Germany_X</th>\n      <th>Greece_X</th>\n      <th>India_X</th>\n      <th>US_X</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Brazil_Y</th>\n      <td>-</td>\n      <td>NO</td>\n      <td>YES</td>\n      <td>YES</td>\n      <td>YES</td>\n      <td>YES</td>\n    </tr>\n    <tr>\n      <th>China_Y</th>\n      <td>YES</td>\n      <td>-</td>\n      <td>YES</td>\n      <td>YES</td>\n      <td>YES</td>\n      <td>YES</td>\n    </tr>\n    <tr>\n      <th>Germany_Y</th>\n      <td>NO</td>\n      <td>YES</td>\n      <td>-</td>\n      <td>YES</td>\n      <td>YES</td>\n      <td>YES</td>\n    </tr>\n    <tr>\n      <th>Greece_Y</th>\n      <td>YES</td>\n      <td>YES</td>\n      <td>NO</td>\n      <td>-</td>\n      <td>YES</td>\n      <td>YES</td>\n    </tr>\n    <tr>\n      <th>India_Y</th>\n      <td>YES</td>\n      <td>NO</td>\n      <td>YES</td>\n      <td>YES</td>\n      <td>-</td>\n      <td>YES</td>\n    </tr>\n    <tr>\n      <th>US_Y</th>\n      <td>YES</td>\n      <td>NO</td>\n      <td>YES</td>\n      <td>YES</td>\n      <td>YES</td>\n      <td>-</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### Results  \n\n<div style='text-align: justify;'>  \nBrazil has a bidirectional relationship with Greece, India, and the US. In addition, China has a bidirectional relationship with Greece and Germany, while Germany has a bidirectional relationship with China, India, and the US. Moreover, Greece has bidirectional relationships with the investigated indices except for the DAX index. Furthermore, India and the US have bidirectional relationships with the investigated markets except for the Chinese one. Another insight is that the rest of the relationships are unidirectional and there is no case of no causal relationship. Even though the Granger causality test does not imply theoretical causality, it is a profound indication that there is statistical causality between the market indices.\n</div>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# References  \n* Dickey, D., & Fuller, W. (1979). Distribution of the Estimators for Autoregressive Time Series With a Unit Root. Journal of the American Statistical Association,, 74(366), 427-431. doi:https://doi.org/10.2307/2286348  \n\n* Engle, R., & Granger, C. (1987). Co-Integration and Error Correction: Representation, Estimation, and Testing. Econometrica, 55(2), 251-276. doi:https://doi.org/10.2307/1913236  \n\n* Granger, W. (1969). Investigating Causal Relations by Econometric Models and Cross-spectral Methods. Econometrica, 37(3), 424-438. Retrieved from https://www.jstor.org/stable/1912791  \n\n* Sims, C. (1972). Money, Income, and Causality. The American Economic Review, 62(4), 540-552. Retrieved from https://www.jstor.org/stable/1806097  \n\n* Brooks, C. (2008). Introductory Econometrics for Finance (2nd ed.). Cambridge University Press.  \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}